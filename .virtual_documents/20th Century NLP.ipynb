





import pandas as pd
import numpy as np
import spacy
from spacy import displacy
import networkx as nx
import os
import matplotlib.pyplot as plt
import scipy
import re


# downloading English module
!python -m spacy download en_core_web_sm


# loading spacy English module
NER = spacy.load("en_core_web_sm")





 with open('Key_events_of_the_20th_century_article_Wiki.txt', 'r', errors='ignore') as file:
    data = file.read().replace('\n', '')


data





#creating a NER object out of the text file 
book = NER(data)


# visualizing identified entities
displacy.render(book[273:20000], style = "ent", jupyter = True)





df_sentences = [] # creating an empty shell to store results

# looping through sentences, getting entity list for each sentence
for sent in book.sents:
    entity_list = [ent.text for ent in sent.ents]
    df_sentences.append({"sentence": sent, "entities": entity_list})
    
df_sentences = pd.DataFrame(df_sentences)


df_sentences.head(10)





countries_df = pd.read_csv("countries_list_20th_century.csv", index_col = 0)


countries_df.head()


#stripping space from country_name to make them the same as what appears in the text
countries_df["country_name"] = countries_df["country_name"].str.strip()





# creating a function to filter out entities not of interest
def filter_entity(ent_list, countries_df):
    return [ent for ent in ent_list 
            if ent in list(countries_df['country_name'])]


df_sentences['country_entities'] = df_sentences['entities'].apply(lambda x: filter_entity(x, countries_df))


df_sentences['country_entities'].head(20)


# filtering out sentences that don't have any country entities

df_sentences_filtered = df_sentences[df_sentences['country_entities'].map(len) > 0]


df_sentences_filtered.head(10)





# defining relationships 

# window size = 5 : this means five sentences will be looked at simultaneously 
relationships = [] # creating an empty list

for i in range(df_sentences_filtered.index[-1]):
    end_i = min(i+5, df_sentences_filtered.index[-1])
    country_list = sum((df_sentences_filtered.loc[i: end_i].country_entities), [])
    
    # removing duplicated countries that are next to each other
    country_unique = [country_list[i] for i in range(len(country_list)) 
                   if (i==0) or country_list[i] != country_list[i-1]]
    
    if len(country_unique) > 1:
        for idx, a in enumerate(country_unique[:-1]):
            b = country_unique[idx + 1]
            relationships.append({"source": a, "target": b})


relationship_df = pd.DataFrame(relationships)


relationship_df 


# sorting the cases with a->b and b->a

relationship_df = pd.DataFrame(np.sort(relationship_df.values, axis = 1), columns = relationship_df.columns)
relationship_df.head(5)


# summarizing the interactions
relationship_df["value"] = 1
relationship_df = relationship_df.groupby(["source","target"], sort=False, as_index=False).sum()


relationship_df.head(10)


#exporting relationship dataframe
#creating path
path = r'C:\Users\canam\OneDrive\Desktop\Career Foundry'


relationship_df.to_csv(os.path.join(path, 'Specialization', '20th-Century', 'country_relationships.csv'))
